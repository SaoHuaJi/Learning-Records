---
name: "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
uri: "https://arxiv.org/abs/2205.10625"
tags: ["Prompt Engineering", "Chain-of-Thought", "Prompting strategy", "Complex reasoning", "LLM"]
type: "paper"
subjects: ["Artificial Intelligence", "Natural Language Processing"]
authors: ["Denny Zhou", "Nathanael Schärli", "Le Hou", "Jason Wei", "Nathan Scales", "Xuezhi Wang", "Dale Schuurmans", "Claire Cui", "Olivier Bousquet", "Quoc Le", "Ed Chi"]
affiliations: ["Google Research, Brain Team"]
year: 2023
venue: "ICLR 2023"
language: "en"
citation: |
    @article{zhou2022least,
        title={Least-to-most prompting enables complex reasoning in large language models},
        author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and others},
        journal={arXiv preprint arXiv:2205.10625},
        year={2022}
    }

importance: 4
difficulty: 2
recommend: 2
---

# 文章名称

## 1. 概览 Overview

### 1.1 个人预览 Personal Preview

> 针对 LLM 在解决超出提示示例难度的问题时表现不佳的现状，文章提出了一种新的提示策略 “由易到难提示（Least-to-Most Prompting，LTM）”。核心思想是先将复杂问题分解成若干易于求解的子问题，再让模型逐一解决这些子问题，并逐步利用前一步的答案来辅助后续求解。实验证明，该策略可以显著增强 LLM 对复杂推理任务的泛化能力。例如，在组合泛化基准 SCAN 上，仅通过少样本提示就使 GPT-3 模型达到了接近 100% 的准确率（远超思维链提示的 16%），展示了提示工程在无需额外训练的情况下大幅提升模型推理水平的潜力。

### 1.2 内容简介 Description

- **研究背景 Research Background：**
大型预训练语言模型结合少样本提示已经在各种推理任务上取得了显著进展，其中尤以 CoT 的效果最为瞩目。CoT 提示通过要求模型给出逐步推理过程，大幅提高了数学计算、常识问答等任务的准确性。然而，现有提示范式往往假设模型在测试时遇到的问题与提示示例的难度相当。当模型面对远超提示示例复杂度的问题时，其表现会急剧恶化。这种从易题到难题的泛化能力不足成为制约 LLM 推理能力的一大瓶颈。
- **研究目标 Research Objectives：**
文章旨在克服上述 “由易到难” 泛化难题，探索如何让 LLM 通过适当的提示在不经额外训练的情况下解决超出示例复杂度的新问题。作者希望设计一种系统性的提示策略，引导模型将复杂任务拆解为更小的子任务并逐一解决，从而提升模型在组合推理、逐步计算等方面的表现。这一目标在实验上通过选择符号操作、组合命令解释、数学应用题等具有代表性的任务来验证，观察新的提示方法能否显著优于传统提示策略。
- **主要贡献 Main Contributions：**
&emsp;&emsp;(1) 提出并定义了 “LTM 提示” 策略，这是一种两阶段的提示方法：首先让模型学习将复杂问题分解为简单子问题，然后让模型利用先前子问题的答案逐步求解后续问题，直至得出最终答案。整个过程完全基于少样本提示，无需额外训练或微调。
&emsp;&emsp;(2) 通过在多个具有挑战性的推理任务上实验，证明了该提示策略的有效性。特别地，在经典组合泛化基准 SCAN 的长度划分测试中，GPT-3 （code-davinci-002）模型在仅提供 14 个示例的情况下借助 LTM 提示达到 99% 以上的准确率（相比之下链式思维提示只有约 16%），甚至超过了需要使用 15000+ 训练样本训练的专门神经符号模型。同样，在单词末字母串联的符号操作任务中，LTM 提示成功泛化到比示例更长的输入串，精度远高于链式提示；在数学算术推理数据集 GSM8K 和阅读理解数据集 DROP 的数值问题上，LTM 策略也均取得比标准提示和链式提示更好的成绩。
&emsp;&emsp;(3) 为提升 LLM 推理能力提供了一种新思路，拓展了现有提示策略的边界。作者指出该策略可以结合 CoT 解题过程或 CoT-SC 解码等现有技术一起使用，但本身已可独立发挥作用。这一工作表明，不通过额外训练，仅通过巧妙的提示设计也能大幅提高模型在复杂任务上的表现，为后续研究提供了借鉴。

---

## 2. 关键信息 Key Information

### 2.1 核心思想与方法 Main Ideas & Methods

- **核心思想：**
LTM 提示的核心在于模拟人类先易后难的解题策略：先将复杂问题拆解为一系列更简单的子问题，然后逐个解决这些子问题，并将每一步的结果用于辅助下一步求解，以此层层推进直至解决原始问题。作者借鉴了教育心理学中的 “least-to-most” 渐进提示理念用于大模型提示设计，让模型也学会 “教” 自己：先回答容易的问题，再利用所得答案解决较难的问题。通过这种逐步递进的方式，模型能够将注意力聚焦于局部子任务，降低单次推理的难度，从而在总体上完成原本复杂度较高的推理。
- **实现方法：**
该策略包括两个顺序执行的阶段：
![Framework](Resources/LTM%20-%20Framework.png)
&emsp;&emsp;(1) 问题分解阶段：模型根据预先设定的 few-shot 提示示例，将给定的复杂问题拆解成若干有逻辑顺序的子问题列表。
&emsp;&emsp;(2) 子问题求解阶段：模型依次回答上述子问题列表中的每个问题。在求解每个子问题时，提示由三部分构成：示例演示、已解子问-答对（如果有），以及当前待解的子问题。模型首先根据示例回答第一个子问题，得到答案后将该问答追加进提示，再询问下一个子问题，以此类推，逐步将先前答案融入后续求解的上下文。最终，伴随最后一个子问题（通常对应原始问题）的解答，模型给出完整的最终答案。整个流程不涉及对模型参数的更新，两阶段均通过精心设计的少样本提示实现，无需额外训练。
作者指出，该方法也可与 CoT 提示和 CoT-SC 解码策略相结合，但并非必要.对于某些简单任务，两阶段甚至可以合并为单次提示完成推理。

### 2.2 实验设置与结果 Experimental Settings & Results

- **实验设置 Experimental Settings：**
为了验证 LTM 提示的有效性，作者在三类具有代表性的任务上进行了评估：一是符号操作任务，如单词末字母串联（给定单词列表，输出每个单词最后一个字母拼接而成的字符串）；二是考察组合泛化能力的 SCAN 指令翻译任务（将自然语言命令转换为动作序列，是知名的组合泛化基准）；三是数学文本推理，包括 GSM8K 算术应用题和 DROP 阅读理解数据集中需要数值推理的问答。在每项任务上，作者将 LTM 提示与思维链提示和标准 few-shot 提示进行对比，主要使用 OpenAI GPT-3 系列模型（如 code-davinci-002）进行推理实验。
在单词末字母串联任务中，提示示例包含了两个不同长度（2 和 3）的单词列表及其正确输出，测试时模型需泛化处理长度远超示例的新单词列表。在 LTM 提示下，模型首先被要求将长单词列表划分为较短的子列表，然后分别求解每个子列表的末字母串联，最后合并结果得到完整答案。对于 SCAN 任务，作者分别构造了“指令分解提示”和“指令求解提示”：前者包含 8 个范例，演示如何将复杂指令拆分为若干简单指令序列；后者包含 14 个范例，演示如何将自然语言指令映射为动作序列。模型先依据分解提示将长指令拆解为简短指令列表，再据此逐条翻译为动作并组合。
在 GSM8K 数学推理中，提示示例仅涉及一个两步求解的简单问题（如先求出一个中间值再求总数），而测试题目可能需要更多步推理。作者在该任务上采用了简化的实现：将问题分解和求解过程编写在同一提示中一并示范（即先在示例中写出“让我们将问题拆解...”的步骤，再演示子问题求解），以测试模型能否从 2 步示例 泛化到 5 步以上 的复杂问题。对于 DROP 数据集，作者选取了其中需要数字推理的问答，对其应用类似的提示拆解方法（例如将问题拆成若干子问，每个子问提取一项相关数值信息）。
- **实验结果 Experimental Results：**
实验结果显示，LTM 提示在各项任务中均超越了现有提示方法。
在单词末字母串联任务上，标准 few-shot 直接提示对长度大于示例的列表完全失败（准确率为 0），思维链提示虽然较基准有所提升但随着列表长度增加性能明显下降；例如当测试列表长度从 4 增至 12 时，CoT 提示准确率从约 84% 下降到 32%，而 LTM 提示仅从 94% 略降至 74% ，展现出更好的长度泛化能力。在 SCAN 任务上，LTM 提示的优势更加突出：在长度拆分的测试集中，GPT-3 code-davinci-002 模型使用链式提示仅达到约 16% 的正确率，而采用 LTM 提示则飙升至 99.7%。即使换用 text-davinci-002 模型，LTM 提示也取得了 76% 的成绩，而链式提示几乎为 0。值得一提的是，LTM 只需提示中的 14 个示例就实现了这一性能，而此前文献中的神经符号模型需要在包含逾 15000 个样本的训练集上训练才能达到可比表现。
在 GSM8K 数学推理任务上，LTM 提示将 GPT-3 模型的总体准确率从链式提示的 60.9% 略微提升至 62.4%；尽管总体增益不大，但对于需要 5 步及以上推理的难题，正确率由 39.1% 提升到了 45.2%，显示出对复杂多步推理场景的优势。在 DROP 数据集中，LTM 提示同样优于链式提示：例如在非 “美式橄榄球” 类的问题中，准确率从 74.8% 提升到 82.5%，在涉及橄榄球背景的问题上也从 59.6% 提升到 73.4%。综合来看，LTM 提示有效地缓解了模型在更高难度测试上的性能退化问题，在多个领域的推理任务上均取得了最优的结果。

---

## 3 分析思考 Analysis & Thoughts

### 3.1 文章结论 Conclusions

文章提出的 LTM 提示策略证明了通过巧妙的提示工程可以显著提高 LLM 对复杂推理任务的解决能力。该方法专注于解决 CoT 提示难以应对的 “由易到难” 泛化难题，成功地让模型在无需额外训练的情况下解决了远超提示示例复杂度的问题。通过在符号操作、组合命令理解和数学推理等任务上的实验，作者展示了 LLM 能够被引导以分解-求解的方式获得类似组合泛化的能力，大幅缩小了测试难度与提示示例难度之间的差距。值得一提的是，对于 LTM 未能正确回答的个别复杂问题，往往只要人为提供一个合理的拆解思路，模型即可顺利求解——这与人类解决棘手问题的过程类似：找到正确的子问题划分就等于解决了一大半问题。综上，Least-to-Most 提示为提升大模型的推理广度和难题处理能力提供了一个有效途径。

### 3.2 个人思考 Personal Thoughts

LTM 提示本质上是证明了良好的任务规划 / 问题拆解能够有效提升模型对复杂任务的泛化能力，因此其最大的问题在于如何实现有效的问题拆解。
一来，一旦初始分解出现偏差，后续的解题过程都将在错误假设上进行，最终答案也将错误且缺乏机制自动纠正。相比之下，后续研究提出的  ToT 通过在每步生成多个想法并进行搜索，可以在一定程度上缓解这一问题，当某一路径不通时能够回溯并尝试其他路径。
二来，设计有效的分解与求解示例对人类提出者来说并非易事。当任务缺乏明显的分解逻辑或问题领域非常复杂时，编写高质量的提示可能需要反复试验。这意味着 LTM 提示在实际应用中需要经验和直觉的支持，不具备像自动微调那样的可移植性。
此外，LTM 策略需要多轮交互（一次分解 + 多次子问题求解），会增加调用开销和提示长度，对模型上下文窗口和推理速度提出了更高要求。
另一个观察是，在 GSM8K 等需要复杂数学推理的任务上，LTM 提示的整体提升幅度有限。这表明对于某些领域，仅靠提示分解也许不足以彻底解决问题，还需要结合模型内在算术能力、外部工具或更多样的推理框架。

---

## 4. 关联文章 Related Works
