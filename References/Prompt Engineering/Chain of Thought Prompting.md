---
name: "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
uri: "https://arxiv.org/abs/2201.11903"
tags: ["NLP", "Prompting", "Prompt Engineering", "Reasoning", "Large Language Models"]
type: "paper"
subjects: ["Artificial Intelligence", "Computation and Language"]
authors: ["Jason Wei", "Xuezhi Wang", "Dale Schuurmans", "Maarten Bosma", "Brian Ichter", "Fei Xia", "Ed H. Chi", "Quoc V. Le", "Denny Zhou"]
affiliations: ["Google Research, Brain Team"]
year: 2022
venue: "NeurIPS 2022"
language: "en"
citation: |
    @article{wei2022chain,
        title={Chain-of-thought prompting elicits reasoning in large language models},
        author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
        journal={Advances in neural information processing systems},
        volume={35},
        pages={24824--24837},
        year={2022}
    }

importance: 5
difficulty: 2
recommend: 3
---

# Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

## 1. 概览 Overview

### 1.1 个人预览 Personal Preview

> LLM 在缺乏明确推理步骤提示的情况下难以解决需要多步推理的复杂任务。即使模型参数规模很大，传统直接问答式提示对数学推理、常识推理等多步问题效果不佳。
> 文章提出了思维链提示（Chain-of-Thought Prompting）方法，在少样本（few-shot）提示词示例中加入问题的中间推理步骤，让模型模仿人类逐步推理的过程，再给出最终答案。这一方法无需额外训练，只通过精心设计的提示就激发了模型的推理能力。
> 实验表明，该方法能显著提升 LLM 在算术、常识和符号推理任务上的表现。尤其是在数学文本题（GSM8K）上，具有思维链提示的 540B 参数模型达到新的 SOTA（58%准确率），超过了之前经过微调+验证器的 GPT-3 模型（55%）。较小模型则几乎没有收益，这种推理能力仅在百亿级以上模型中 “涌现” 。
> 这项工作表明了 LLM 蕴含的推理潜力：通过巧妙设计提示即可引导模型逐步思考，而不必额外训练。因此，提升 LLM 性能的方式也可以是思考如何通过上下文工程来发掘模型的新能力，以及在资源受限的模型中如何模拟类似的推理过程。

### 1.2 内容简介 Description

- **研究背景 Research Background：**
随着参数规模增长，LLM 在许多 NLP 任务上表现提升，但在需要多步推理的任务上依然表现不佳。传统少样本提示方法（如 GPT-3）只提供问答对示例，模型直接输出答案，难以处理算术推理、常识推理等复杂任务。此前也有工作尝试通过自然语言推理链提升模型推理能力，例如从零训练或微调模型生成中间步骤。然而，大规模收集高质量推理步骤数据代价高，而且单纯扩大模型规模不足以解决复杂推理。
- **研究目标 Research Objectives：**
文章旨在结合 “生成中间推理步骤” 与 “大模型少样本提示” 两种思路的优点，在无需额外训练的情况下激发 LLM 的复杂推理能力。具体目标包括：设计一种提示策略，让模型在输出答案前生成一系列中间推理步骤（即 “思维链” ），并验证该方法在不同类型推理任务中的有效性，以及探究这种能力对模型规模的依赖。
- **主要贡献 Main Contributions：**
&emsp;&emsp;(1) 方法创新：提出了思维链提示方法，将示例构造成 “问题-思维链-答案” 三元组，使模型在回答问题时先产生逻辑推理过程，再给最终答案。这一方法简单直观，无需改变模型参数，却显著提升了模型的推理表现。
&emsp;&emsp;(2) 实验证明：系统评估了算术、常识、符号推理任务，结果显示思维链提示相比标准提示有大幅性能提升。特别是，在 GSM8K 数学题等复杂任务上，540B 参数模型通过 8 个带思维链的示例达到新的状态水平。模型规模在约 100B 以上时才出现显著增益，小模型基本无改善，这表明该推理能力是一种 “智能涌现” 现象。
&emsp;&emsp;(3) 深入分析：作者分析了模型生成的思维链，发现当模型给出正确答案时，其推理链通常也是合乎逻辑的；而错误答案往往伴随推理链中的漏洞。此外，通过消融实验排除了其它因素（如仅增加计算量）的作用，证实性能提升确实来自于自然语言推理链本身。作者也讨论了该方法的局限及未来改进方向。

---

## 2. 关键信息 Key Information

### 2.1 核心思想与方法 Main Ideas & Methods

思维链提示的核心是在少样本提示词中显式加入中间推理过程。具体做法是：针对给定任务，人工构造若干示例，每个示例包括输入问题、推理过程、最终答案三部分，以自然语言呈现。模型阅读这些示例后，再对新问题进行推理和作答。通过在示例中展示逐步推理，模型被引导模仿这种 “逐步思考” 的过程，从而在复杂问题上也能产出合理的推理链和正确答案。这种方法等于在输出空间对模型进行提示，使其生成解释性的中间步骤（不同于以往在输入上附加指令或特殊标记的提示方法）。值得注意的是，思维链的能力只有在模型参数足够大的情况下才被有效激发：作者在多种规模的模型上比较发现，小模型即使按照该提示也往往生成流畅但不正确的推理，而只有规模达到百亿级时才开始表现出逻辑一致的推理能力。
![思维链提示示例](Resources/Chain%20of%20Thought%20Prompting%20-%20CoT%20prompt.png)
思维链提示方法具有多方面的优点：首先，它允许模型将复杂问题拆解为更易解决的子问题，针对需要更多步骤的任务可以投入更多 “思考” （生成更多中间文字）。其次，模型生成的思维链提供了可解释性窗口，使我们可以观察模型是如何推导答案的，有助于分析模型错误原因。第三，该方法适用于数学、常识、符号操作等广泛的任务，只要人类可以通过语言分步解决的任务，理论上模型也能受益于链式推理。最后，也是这项工作的重要发现：不需要额外训练，只需给现有的 LLM 添加包含推理步骤的提示示例，就能让模型表现出这种链式推理能力。这一点降低了使用门槛：一个预训练好的大模型配合适当提示，就能 “一促即会” 地解决多种复杂任务。

### 2.2 实验设置与结果 Experimental Settings & Results

- **实验设置 Experimental Settings：**
为评估思维链提示的效果，研究者在三类任务上进行了实验：算术推理（如数学文字题）、常识推理（需要日常常识和推理的问题）、符号推理（逻辑推理或符号操作的任务）。选取的具体基准包括：
&emsp;&emsp;(1) 算术：GSM8K（大型数学文字题数据集）、SVAMP、ASDiv、AQuA、MAWPS 等多个数学题数据集，用于测试模型的多步计算和运算推理能力。
&emsp;&emsp;(2) 常识：CommonsenseQA、StrategyQA 以及 Big-Bench 中的日期推理（Date Understanding）和体育理解（Sports Understanding）任务，评测模型对常识性问题和需要背景知识的问题的推理表现。
&emsp;&emsp;(3) 符号：“最后一个字母连接” 任务（给出姓名，要求连接各单词最后一个字母）和 “抛硬币” 任务（描述一系列有人翻转或不翻转硬币的操作，问硬币是否仍然正面朝上）。这些任务注重考察模型处理抽象符号和逻辑规则的推理能力。
模型方面，实验涵盖了多种规模的预训练语言模型，包括 OpenAI 的 GPT-3 系列（参数规模约为 0.1B 至 175B）、Google 的 LaMDA 系列（0.4B 至 137B）、PaLM 系列（0.8B 至 540B），以及较新的 UL2 20B 和 Codex 模型等。通过在同一模型的不同规模版本上测试，作者可以观察模型规模对链式提示效果的影响。每个任务都采用少样本设置：使用少量（如 8 个）示例构造提示。其中标准提示只给出问题-答案对，而链式提示则给出问题-推理过程-答案三元组示例。在提示中，推理过程由作者手工编写（确保正确合理）。模型在测试问题上使用贪婪解码生成答案（部分实验也考察了不同随机种子或投票策略的影响）。

- **实验结果 Experimental Results：**
思维链提示显著提升了 LLM 在各类推理任务上的性能，并呈现出以下关键现象：
&emsp;&emsp;(1) 推理能力的涌现： 小规模模型基本无法从链式提示中获益，而当模型参数增至 100B 级时，链式提示的效果突然变得显著。换言之，链式推理是伴随模型规模增长而涌现的能力。作者发现，对于规模较小的模型（如数亿参数），加入思维链反而可能使性能略降，因为模型会生成不正确的 “伪推理”。而当规模达到约 100B 以上时，模型开始产生有用的推理链，带来明显的准确率提升。这一趋势在算术任务中尤为明显：例如在数学题 GSM8K 上，标准提示的表现随模型大小几乎停滞不前，而链式提示的表现则在大模型上陡然上升（solve rate 从不足 20% 飙升到近 60%）。这证实了作者提出的观点：思维链提示的有效性取决于模型具备足够的基础语言理解和生成能力，规模是催化剂。
![思维链提示对模型规模的影响](Resources/Chain%20of%20Thought%20Prompting%20-%20Experiments.png)
&emsp;&emsp;(2) 难度越大，提升越大： 链式提示对复杂任务的帮助尤为突出。实验显示，在简单任务（例如仅需一步推理即可的算术题）上，链式提示带来的改进很小甚至略有负影响，因为这些任务不需要中间推理步骤即可直接回答。相反，对于需要多步推理的困难任务，链式提示让大型模型的表现大幅超越标准提示。例如，在最具挑战性的 GSM8K 数据集中，使用链式提示的 PaLM 540B 模型正确率超过 58%，而相同模型用标准提示仅约17.9%，提升了两倍有余。又如在常识推理的 Sports Understanding 任务中，PaLM 540B 使用链式提示达到 95.4% 准确率，远高于模型直接输出答案的 84%，甚至超过了一位不借助工具的人类体育爱好者的成绩。总体而言，任务越复杂（需要推理步骤越多），链式提示相对于直接答案提示的优势就越明显。
&emsp;&emsp;(3) 超越微调 SOTA： 借助思维链提示，大模型在无需额外训练的情况下达到了或接近了多项任务的最新领域最佳水平。以数学任务为例，PaLM 540B+链式提示在 GSM8K 上取得 58% 的解题正确率，刷新了当时该任务的纪录。此前的最佳是 GPT-3 175B 通过大规模有监督微调并结合验证器达到的 55%。也就是说，仅凭提示就让通用大模型在专业任务上超越了专门训练的模型。这种现象在其他数据集上也有所体现：如 SVAMP 和 MAWPS 算术题，PaLM+CoT 达到新的 SOTA；在 AQuA 和 ASDiv 上也逼近已微调模型的性能，相差不到 2%。另外在常识任务 StrategyQA 上，链式提示的 PaLM 540B 达到 75.6% 准确率，也超过了之前微调模型 69.4% 的水平。这些结果强调了思维链提示的价值：通过巧妙设计提示，预训练模型即可在不少任务上媲美甚至超越需要昂贵微调才能达到的表现。
&emsp;&emsp;(4) 符号推理与泛化： 在符号推理任务上，链式提示同样展现了强大效果，同时揭示了模型在长度泛化上的潜力。对于 “最后字母连接” 和 “抛硬币” 这类任务，使用链式提示的 PaLM 540B 在与示例长度相似的测试问题上取得了接近 100% 的解题率（几乎全对），而小模型即使看了推理示例仍基本失败。这再次说明只有足够大的模型才能真正运用推理链来解决问题。更有趣的是，当测试问题的复杂度超出提示示例范围（例如要求连接更多单词的首尾字母，或经历更多次抛硬币操作），标准提示下模型完全崩溃（几乎全错），但链式提示下大模型仍能一定程度上保持性能，并且随着模型规模增大性能提升。也就是说，思维链提示帮助模型在一定程度上实现了超出训练示例长度的泛化，能够处理比提示中示例更长的推理链。这对提升模型解决更复杂推理问题的能力具有启发意义。

---

## 3 分析思考 Analysis & Thoughts

### 3.1 文章结论 Conclusions

- **总结：**
文章证明了通过在提示词中引导 LLM 生成中间推理步骤，可以大幅提升模型的推理能力。这一思维链提示方法简单而通用，不需额外数据或微调，却让模型能够解决原本无法胜任的多步骤任务。大量实验证据支持其有效性：在算术、常识、符号推理三大类任务中，链式提示均显著优于直接答案输出，尤其是在参数规模极大的模型上效果突出。模型规模被发现是推理能力涌现的关键因素，链式推理能力只有在百亿级参数以上才自然出现。因此，思维链提示拓展了 LLM 的能力边界，让原本随规模增长停滞的任务性能出现突破性提升。这项工作表明：标准的提示方法仅挖掘了大模型能力的下限，而通过设计合理的思维链提示，可以激发其潜在的更强推理能力。作者希望这种方法能够启发更多关于基于语言的推理策略研究，进一步扩大语言模型可以胜任的任务范围。
- **意义：**
思维链提示的提出在 LLM 领域产生了重大影响。一方面，它提供了一种新范式来提升模型复杂推理能力，不需要训练开销，这对于快速适配模型解决新问题极具价值。另一方面，该方法揭示了 AI 系统中推理过程显式化的巨大作用——让模型 “想出来” 而非直接给答案，可以获得更好的结果。这为构建可解释、高性能的 AI 推理系统指明了方向。此外，作者的发现引出了 “涌现能力” 这一重要概念，引发了后续许多关于模型规模与能力非线性增长的探讨。总的来说，思维链提示拓宽了人们对预训练语言模型潜力的认识，证明通过巧妙的人机交互设计即可挖掘出模型新的能力，而这在模型算法和训练之外打开了一个新维度的改进途径。

### 3.2 个人思考 Personal Thoughts

- 文章最大的意义在于证明了 LLM 可以通过修改提示词的方式大幅提高模型性能，再一次证明了提示词工程的重要性，并给出了思维链提示范例，为后来的研究者指明了方向。
- 不足之处在于该思维链提示方法仅适用于大规模模型，对于小规模模型效果并不明显，并且需要一定的人工工作来编写推理过程。
- 该文章为后续相关方向的研究奠定了基础：如零样本 CoT（提示词里加一句 “让我们一步步思考”）、自动 CoT 生成、工具集成、自洽 CoT 等。

---

## 4. 关联文章 Related Works

- Zero-shot CoT
- Auto CoT
- CoT-SC
- Tree of Thoughts Prompting
