---
name: "Tree of Thoughts: Deliberate Problem Solving with Large Language Models"
uri: "https://arxiv.org/abs/2305.10601"
tags: ["思维树", "LLM", "启发式搜索", "提示工程", "推理规划"]
type: "paper"
subjects: ["Computation and Language", "Artificial Intelligence", "Machine Learning"]
authors: ["Shunyu Yao", "Dian Yu", "Jeffrey Zhao", "Izhak Shafran", "Thomas L. Griffiths", "Yuan Cao", "Karthik Narasimhan"]
affiliations: ["Princeton University", "Google DeepMind"]
year: 2023
venue: "NeurIPS 2023"
language: "en"
citation: |
    @article{yao2023tree,
        title={Tree of thoughts: Deliberate problem solving with large language models},
        author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
        journal={Advances in neural information processing systems},
        volume={36},
        pages={11809--11822},
        year={2023}
    }

importance: 5
difficulty: 4
recommend: 4
---

# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

## 1. 概览 Overview

### 1.1 个人预览 Personal Preview

> 针对 LLM 在复杂问题求解中的局限，文章提出了一种通用推理框架 “思维树”（Tree of Thoughts, ToT）。该方法通过让模型在推理过程中探索多个可能的思路路径，并由模型自身对中间结果进行评估，从而实现更深思熟虑的决策过程。实验结果表明，相比传统的思维链（Chain-of-Thought, CoT）等提示技巧，思维树显著提升了模型在数学推算、规划创作、解谜等任务上的求解能力。例如，在 24 点游戏中，GPT-4 使用思维链仅取得 4% 的成功率，而应用思维树框架后成功率高达 74%。

### 1.2 内容简介 Description

- **研究背景 Research Background：**  
传统的 LLM 推理往往采用从输入到输出直接生成或思维链等顺序决策过程。这种基础为原始的自回归机制的从左到右逐 token 贪心式的生成方式在需要探索、策略性前瞻或需要全局规划的任务中表现不佳。为解决此类复杂问题，近期有研究者尝试引入类似人类 “System 2” 慢思考的机制，为语言模型提供更有计划性的推理能力。思维链提示通过引导模型生成中间推理步骤在一定程度上改善了复杂推理；Self-Consistency 策略则通过对同一问题采样多条思维链并投票输出最可能答案缓解了单一路径的不稳定性。然而，这些方法仍存在局部探索不足、缺乏全局搜索等局限。

- **研究目标 Research Objectives：**  
文章旨在推广和一般化思维链的推理范式，提出一种让 LLM 能够 “货比三家、三思而后行” 的推理框架。具体目标包括：
&emsp;&emsp;(1) 通过显式维护一个由可能中间步骤组成的 “思维树”，允许模型在不同分支间进行搜索和回溯，以提升决策的全局最优性。
&emsp;&emsp;(2) 结合启发式评估，让模型能够自主评估当前部分解的前景，从而指导后续搜索方向。
&emsp;&emsp;(3) 验证该框架在多种需要规划或搜索的任务上的有效性，探究其在提升模型复杂问题求解能力方面的潜力。

- **主要贡献 Main Contributions：**  
&emsp;&emsp;(1) 提出框架：首次提出 “思维树” 大语言模型推理框架，将问题求解过程形式化为在一棵树上搜索解空间，各节点为中间思维状态，允许模型在推理中进行多分支探索和全局规划。这一框架概括了思维链（CoT）、自洽思维链（CoT-SC）等已有方法，将它们视作思维树的特例。  
&emsp;&emsp;(2) 方法机制：设计了思维树推理的完整流程，包括问题分解、思维生成、状态评估、搜索算法四个模块。提出了两类思维生成策略（独立采样和顺序提议）与两类状态评估策略（独立评估和跨状态投票），并将经典搜索算法（BFS / DFS）引入 LLM 推理，实现带前瞻和回溯的系统性搜索。  
&emsp;&emsp;(3) 实验验证：构建了三个具有挑战性的任务（24 点算术游戏、创意写作、填字游戏）来评估思维树方法。在这些任务上，与直接 IO 输出、CoT、CoT-SC 等相比，思维树大幅提升了 GPT-4 等模型的性能。例如在 24 点任务上成功率提高数十倍，在开放式写作任务上输出连贯性显著增强，在迷你填字游戏上解决完整谜题的数量从几乎为零提升到 20。

---

## 2. 关键信息 Key Information

### 2.1 核心思想与方法 Main Ideas & Methods

- **核心思想：**
思维树方法的核心是在推理过程中显式地构建一个分叉的 “思维” 搜索树，让模型可以同时探索多个不同的中间推理路径，并通过自我评估选择最有前途的分支继续推进。
![Framework](Resources/Tree%20of%20Thoughts%20Prompting%20-%20Framework.png)
每个节点代表当前问题的一个状态（即已给定输入和迄今生成的思维序列），其中绿色节点表示被保留的候选思维路径，而从节点延伸出的分支表示可以将该状态转换为下一状态的一个思考步骤（又称 “思维”）。与传统一次生成到底的方法不同，思维树允许模型在每一步做出多种假设，再通过面向全局的评估机制筛选决策，从而实现类似启发式搜索的效果：既可以向前展望规划，也能在必要时回溯重新选择。

- **实现方法：**
为了在 LLM 中实现上述思想，作者将思维树推理过程拆解为以下四个模块：
&emsp;&emsp;(1) 思维分解：根据任务性质，将问题求解划分为若干步连贯的中间思维单元（思维）。思维的粒度需要足够 “大” 以便模型能够判断其是否有助于解题，但也要足够 “小” 以确保模型能生成多样且有意义的选项（例如 24 点算术的每步是一个简单方程，填字游戏的每步是填入一个单词）。  
&emsp;&emsp;(2) 思维生成：即给定当前状态，由模型提出可能的下一步思维。作者探讨了两种策略：一是独立采样（sampling），即使用思维链风格的提示让模型一次生成完整的一系列可能思路，然后从中选取多个不同想法；二是顺序提议（sequential proposing），即采用特殊的 “提议提示”，让模型在当前状态下依次给出一个潜在下步想法，如同人类逐步探索下一步动作。前者适用于思维空间较丰富（如每步是段落）的任务，后者适用于空间较受限（如每步只是一行方程或单词）的任务。  
&emsp;&emsp;(3) 状态评估：即为当前前沿的一组候选状态估计它们朝向最终目标的进展程度，用于指导搜索过程的启发式。作者同样提出了两种评估方式：一是独立评估（value evaluation），对每个状态分别用模型进行推理打分或分类，例如判断达到最终解的可能性是 “确定 / 可能 / 不可能” 等。这种评估可结合快速尝试（如简单模拟后续步骤）和常识约束（如 “数字总和太小不可能达成24” ）来粗略判定状态好坏。二是跨状态投票（vote evaluation），即让模型在一个提示中对比多个候选状态，从中票选出最有希望成功的状态。这种方式在单个状态难以独立评估优劣时（例如开放式写作的多种构思比选）会更有效。  
&emsp;&emsp;(4) 搜索算法：最后，在思维树框架下可以灵活套用不同的搜索策略来遍历这棵树。作者主要探讨了两种经典算法：其一是宽度优先搜索（BFS），在每一层保留评分最高的 b 个候选状态，然后再对这些进行扩展。BFS 适合解空间分支较多但深度有限的任务，例如 24 点（深度 3）和创意写作（深度 2），可以在初期就筛掉大部分不良思路。其二是深度优先搜索（DFS），每次优先深入最有希望的分支直至达到解答或被评估为无解，再回溯进行下一分支。DFS 适合解空间深而复杂但分支相对可控的任务，如填字游戏，需要不断尝试填字直到遇到矛盾再回退。通过以上模块的配合，思维树框架让 LLM 在推理时具备了类似 AI 规划中的启发式搜索能力，在无需额外训练的情况下显著提升解决复杂任务的成功率。

### 2.2 实验设置与结果 Experimental Settings & Results

- **实验设置 Experimental Settings：**  
为了验证思维树的有效性，作者选取了三个各具特点的任务：24 点游戏、创意写作和迷你填字游戏。这些任务使用标准的 GPT-4 模型在零样本设置下进行评估，每个任务均设计了不同的成功判定指标：
&emsp;&emsp;(1) 对于 24 点（数学算式推理），从在线题库中选取了 100 道高难度算术题，要求模型输出使用给定 4 个数字得到 24 的算式，成功标准为算式正确且使用所有数字一次。
![Game of 24](Resources/Tree%20of%20Thoughts%20Prompting%20-%20Game%20of%2024.png)
&emsp;&emsp;(2) 对于创意写作（故事生成），输入为 4 个不相关的句子，要求模型生成包含 4 段且每段结尾是这 4 个句子的故事，采用 GPT-4 给出的连贯性评分（1-10 分，取平均）以及人工偏好测试作为评价输出质量的指标。
![Creative Writing](Resources/Tree%20of%20Thoughts%20Prompting%20-%20Creative%20Writing.png)
&emsp;&emsp;(3) 对于迷你填字（5×5 单词填字游戏），输入为横竖各 5 个提示，要求模型填出完整的字母填字板，评估指标包括字母正确率、单词正确率和谜题完全解出率三个层次。
![Mini Crosswords](Resources/Tree%20of%20Thoughts%20Prompting%20-%20Mini%20Crosswords.png)
实验中，对比了多种提示策略的表现，包括直接输入输出（IO）提示、CoT、CoT-SC，以及在部分任务上使用的答案自我改进（iterative refine）方法。所有基准均以多次采样取平均性能，并在 CoT-SC 中通过投票选出最频繁答案。思维树方法本身则根据任务特点选择了合适的思维粒度和搜索策略：在 24 点和写作任务中采用 BFS 搜索有限深度的解空间，在填字游戏中采用 DFS 深度搜索以处理更长的推理链条。

- **实验结果 Experimental Results：**  
实验结果清晰地表明了思维树对复杂任务求解能力的提升。
&emsp;&emsp;(1) 在 24 点任务中，直接 IO 提示、CoT 和 CoT-SC 的成功率分别仅为 7.3%、4.0%、9.0%；相比之下，应用思维树后，即使每层仅展开一个候选（b=1）成功率已跃升至 45%，展开五个候选（b=5）时更是达到 74%。这一巨大优势源于思维树能够有效避免 “一条路走到黑” 的错误路径：分析发现，约 60% 的 CoT 推理在第一个步骤就走向了死胡同，而思维树通过并行探索多种可能一步，大大降低了过早犯错的概率。  
&emsp;&emsp;(2) 在创意写作任务中，思维树同样展现了更优的规划能力。定量评估上，思维树生成的故事平均连贯评分为 7.56，显著高于直接生成（6.19）和先规划再生成的 CoT 方法（6.93）。在人工对比测试中，评审更是偏好思维树输出：在 100 对比较中，有 41 例更喜欢思维树生成的故事，仅 21 例偏好 CoT，其余认为不分伯仲。这表明思维树能够帮助模型产出逻辑更严谨、衔接更自然的长篇文本。而进一步结合迭代优化，能将思维树的平均得分再提升（从 7.56 提高到 7.91），几乎追平人工修改效果。  
&emsp;&emsp;(3) 在迷你填字任务中，面对庞大的组合搜索空间，单纯依赖语言模型自身很难完成谜题：IO 提示和 CoT 方法仅能解出不到 1% 的完整谜题。思维树通过深度优先的系统探索，实现了 20% 的谜题完全解出率；在局部指标上，填入的字母和单词分别有约 78% 和 60% 是正确的，大幅超出传统提示方法的 40% 和 15% 左右。消融实验也验证了启发式评估与搜索策略对性能的贡献：若不使用评估启发直接 DFS 暴力搜索或不允许回溯则完整谜题解出率将降至仅 5%，说明评估剪枝和回溯机制对复杂推理至关重要。
总的来说，这些结果充分证明了思维树能够显著扩展 LLM 在复杂推理任务上的能力边界。

## 3. 分析思考 Analysis & Thoughts

### 3.1 文章结论 Conclusions

- **增强 “System 2” 式推理：**
文章通过构建思维树框架，赋予了 LLM 一种全新的深度推理范式。相比传统的逐步贪心生成，思维树引入了全局规划与搜索，使模型可以跳出单一路径的局限，进行更审慎的决策。实验证明，这种接近人类 “慢思考” 的过程对某些需要策略探索的任务至关重要：哪怕是当前最先进的 GPT-4 模型，在不借助该框架时也难以解决这些任务，而借助思维树则取得了突破性结果。这一发现表明，大模型的推理能力仍有巨大的提升空间，可以通过引入搜索规划等经典 AI 思想来弥补。
- **方法泛化性与局限：**
思维树框架具有相当的通用性和模块化，可视为对多种现有提示策略的统一（如 IO、CoT、自洽都可被看做特定形态的树搜索）。它不依赖额外训练即可部署在现有模型上，并灵活适配不同问题类型。然而，这种基于生成式模型内部搜索的方案也存在一些限制：一方面，其计算开销较大，在实验中往往消耗比普通 CoT 推理多出数十倍的 token 数量；另一方面，思维树的效果依赖于模型对中间状态的评估能力，当前这仍是一种启发式且不完美的估计，可能出现评估偏差导致的次优搜索。此外，为不同任务设计合适的思维表示和提示也是一项需要依赖先验知识的工作（例如本研究中人为指定了每个任务的思维步长），这为通用自动化的应用带来挑战。总的来说，思维树为提升 LLM 复杂推理开辟了一条新路径，但其在更广范围内的适用性与高效性还有待后续研究进一步优化。

### 3.2 个人思考 Personal Thoughts

- **与人类解题的类比：** 思维树的思想与早期认知科学对人类问题求解的模型如出一辙：人类在解决复杂问题时，也常常会同时考虑多个方案、来回权衡取舍，再逐步收敛到最终答案。将这一点引入 LLM 推理，使模型具备类似的 “试探-评估-调整” 循环，无疑是让 AI 更接近人类智力的一种有益尝试。值得注意的是，这种方法本质上将**搜索算法与大模型内置的世界知识相结合**，利用模型自身去评估下一步行动，这种自反性的使用很巧妙，也显示出大模型不仅可以生成内容，还可以在一定程度上监督自己的决策。
- **应用前景与改进：** 鉴于思维树在难题上的显著成效，可以预见这一范式将激发更多后续工作。例如，未来或可针对性地训练语言模型提高 “思维评估” 的可靠性，或者引入强化学习让模型学会何时应当分叉思考、何时回溯检讨，从而减少不必要的探索开销。又比如，将思维树与工具使用、知识检索相结合，构建能够一边搜集外部信息一边规划求解的混合智能体，也是一条值得探索的方向。另外，在特别复杂或开放性的任务上，完全依赖模型自己评估可能不够稳健，引入人工反馈或更明确的奖励信号或许能进一步提升多智能体协作解题的效率。
- **与其它范式的比较：** 思维树与之前的一些大模型推理增强技术既有联系又有区别。例如，思维链自洽通过独立采样多条推理链再投票，其实是一种被动的 “事后多数表决” ，而思维树则属于主动的 “过程内搜索” ，能动态决定探索方向。再如，ReAct 等将推理与环境交互相融合的代理框架更强调和外界互动，而思维树专注于模型内的思考流程优化。如果将各种方法比作登山策略，普通 CoT 像是盲走直线，自洽是多次盲走选最多，ReAct 是借助向导（工具）探路，而思维树则是在关键岔路口分身踏勘，最终择优攀登。不同场景下这些方法各有优劣，如何融合它们的长处也是未来值得探索的问题。

---

## 4. 关联文章 Related Works

- Chain of Thought Prompting
- CoT-SC
- Graph of Thoughts Prompting
- ReAct
