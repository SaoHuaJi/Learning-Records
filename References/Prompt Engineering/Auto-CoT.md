---
name: "Automatic Chain of Thought Prompting in Large Language Models"
uri: "https://arxiv.org/abs/2210.03493"
tags: ["思维链", "自动提示", "LLM", "提示工程", "少样本推理"]
type: "paper"
subjects: ["Computation and Language", "Artificial Intelligence"]
authors: ["Zhuosheng Zhang", "Aston Zhang", "Mu Li", "Alex Smola"]
affiliations: ["Shanghai Jiao Tong University", "Amazon Web Services", "Amazon Web Services", "Amazon Web Services"]
year: 2023
venue: "ICLR 2023"
language: "en"
citation: |
    @article{zhang2022automatic,
        title={Automatic chain of thought prompting in large language models},
        author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
        journal={arXiv preprint arXiv:2210.03493},
        year={2022}
    }

importance: 5
difficulty: 2
recommend: 3
---

# Automatic Chain of Thought Prompting in Large Language Models

## 1. 概览 Overview

### 1.1 个人预览 Personal Preview

> 针对 LLM 推理过程中的提示设计问题，文章提出了一种自动思维链（Auto-CoT）方法以取代人工构造示例。通过让模型自己生成用于演示的中间推理步骤，Auto-CoT 在无需人工干预的情况下实现了与人工设计示例相当甚至更优的推理性能。该方法显著降低了提示工程的人力成本，表明大型模型具备自我构造思维链以提升推理表现的潜力。

### 1.2 内容简介 Description

- **研究背景 Research Background：**
LLM 可以通过思维链（Chain-of-Thought, CoT）将复杂问题分解为一系列中间推理步骤来提高回答准确性。然而，以往最有效的 CoT 提示范式依赖于人工精心设计的少样本示例，即为特定任务手工编写问题及其解题思路。这种人工思维链（Manual-CoT）策略虽然性能出色，但存在成本高、扩展性差的问题。后面的零样本思维链（Zero-Shot-CoT）方法，只需在问题后附加一句 “让我们一步一步思考” 即可引导模型进行多步推理，然而其效果相对有限，难以完全匹敌人工示例提示的表现。
- **研究目标 Research Objectives：**
针对上述局限，文章旨在探索能否自动构建链式思维示例来替代人工设计。核心目标是在无需人工参与的前提下，让模型自动生成多样化的示例问题及其推理过程，并通过将这些自动生成的示例用于少样本提示，从而在推理任务上达到与人工 CoT 示例相媲美的性能。换言之，作者希望证明大型模型自身可以充当“提示工程师”，生成有效的思维链示例来提升推理能力。
- **主要贡献 Main Contributions：**
&emsp;&emsp;(1) 提出了一个自动思维链提示方法 Auto-CoT。该方法利用 LLM 自己的零样本推理能力来自动构造示例（包括问题、推理链和答案），彻底摆脱了人工手动编写示例的需求。
&emsp;&emsp;(2) 引入了多样性采样的策略来增强自动构造示例的质量。通过对候选问题进行聚类并从不同簇中抽取代表性问题，结合零样本 CoT 生成多样化的推理链，减少了自动生成链条中错误的累积和误导影响。作者的分析表明，多样性对于减轻错误推理链的负面作用至关重要。
&emsp;&emsp;(3) 在算术、常识、符号推理等 10 个基准任务上进行实验，结果显示 Auto-CoT 在 GPT-3 上的表现与人工 CoT 提示相当或更优。这证明了无需人工参与仅通过模型自身就能实现高级的链式推理提示设计，为降低大型模型应用中的提示设计成本提供了可行方案。

---

## 2. 关键信息 Key Information

### 2.1 核心思想与方法 Main Ideas & Methods

- **核心思想：**
不再依赖人工编写示例来实现思维链提示，而是让模型自动产生自己的推理示例。具体而言，利用预设的 Zero-shot CoT 提示，让 LLM 在零样本条件下为若干代表性问题生成带有中间推理过程的答案。这些自动生成的 “问题-思维链-答案” 示例经过筛选后被用作 Few-Shot 提示，从而引导模型在回答新问题时也产出连贯的推理过程和正确答案。该思想的关键在于：示例问题的多样性能够缓解模型在自我推理时可能出现的错误，一个模型生成的有误的推理链示例不至于误导后续推理。

- **实现方法：**
Auto-CoT 方法包括两大阶段：
&emsp;&emsp;(1) 问题聚类：首先对任务中的问题进行聚类，以确保挑选出风格和语义各异的示例问题。作者使用 Sentence-BERT 将问题编码为向量，并采用 k-means 等算法将其分成 k 个簇（例如 k=8）。聚类的目的是保证所选示例涵盖不同类型的问题，从而提供多样化的推理示范。
&emsp;&emsp;(2) 示例生成：从每个簇中选取一个代表性问题，并由 LLM 在该问题上执行零样本链式思维推理。具体做法是对每个选定问题附加提示语 “让我们一步一步地思考”，让模型产出该问题的逐步推理过程和答案。为提高生成质量，采用了一些简单启发式规则过滤不良示例：例如不选择长度超过 60 个词的超长问题，舍弃推理步数多于 5 步的冗长解答等。经过此过程，每个簇会产出一个包含 “问题+推理链+答案” 的示例。最后，将来自不同簇的 k 个自动生成示例组合起来，构造出少样本提示所需的演示集。
&emsp;&emsp;(3) 推理应用：在回答新的测试问题时，将上述自动构建的 k 个示例连同新的问题一起提供给模型作为提示输入。由于这些示例展示了模型自己“思考”的过程，模型随即在回答新问题时也倾向于先生成中间推理步骤再给出答案，从而实现链式推理。

### 2.2 实验设置与结果 Experimental Settings & Results

- **实验设置 Experimental Settings：**
作者在十个公开的推理任务上评估了 Auto-CoT 的有效性，包括算术推理（如 MultiArith、GSM8K、AQUA、SVAMP 等）、常识推理（如 CommonsenseQA、StrategyQA）和符号推理（如 Last Letter Concatenation、Coin Flip）等多种类型的问题。实验主要使用 GPT-3 175B 模型作为被提示的基础模型。比较基线包括：

| 基线 | 设置 |
| - | - |
| Zero-Shot（零样本直接推理） | 不提供任何示例，模型直接给出答案 |
| Zero-Shot-CoT（零样本思维链） | 在问题后附加通用提示语如 “让我们一步一步思考”，引导模型先输出推理过程再回答 |
| Few-Shot（少样本直接提示） | 提供若干人工挑选的示例问答（不含显式推理过程）作为提示 |
| Manual-CoT（人工思维链提示） | 提供少样本人工编写的问答示例，每个示例都包含详细的推理步骤和答案 |

- **实验结果 Experimental Results：**
实验结果表明，Auto-CoT 方法取得了与人工 CoT 示例几乎相当甚至更佳的表现。在大多数任务上，Auto-CoT 的推理准确率与采用人工精心设计示例的 Few-Shot CoT 相差无几，有些情况下甚至略有超出。这一成果极大地缩小了人工与自动提示在效果上的差距。例如，在经典的数学推理数据集 GSM8K 上，Auto-CoT 与 Manual-CoT 提示均能使 GPT-3 的准确率提升到远高于零样本水平的相近值。总体来看：
- 相较于零样本直接作答，加入思维链显著提升了模型性能，而 Auto-CoT 和 Manual-CoT 提示的提升幅度最大，说明链式示例对于复杂推理任务是必要的。
- 相较于仅添加 “一步步思考” 的 Zero-shot CoT 策略，Auto-CoT 通过提供完整示例进一步大幅提升了准确率，表明仅有通用指示不如具体示例来得有效。
- 相较于人工少样本无推理示例，Auto-CoT 同样展现出明显优势，这证明了提供中间推理步骤对模型推理能力的增强作用。
此外，作者还分析了不同示例选择策略的影响：如果采用检索与测试问题相似的问例来生成思维链（Retrieval-Q-CoT），往往因示例中潜在的错误而误导模型推理；而 Auto-CoT 的多样性采样策略有效避免了相似性误导，提高了鲁棒性。总之，Auto-CoT 方法成功地在无需人工参与的情况下达到了与最优人工提示相当的效果，显著降低了链式提示应用的门槛。

---

## 3 分析思考 Analysis & Thoughts

### 3.1 文章结论 Conclusions

- **自动示例可行性：**
文章结论证明，大型语言模型可以自动生成高质量的链式推理示例，用于提升自身的推理表现。这表明一些过去需要人工调整的提示工程工作可以由模型自动完成，减少了对人工提示设计的依赖。Auto-CoT 的成功意味着在提示工程中，我们可以更充分地利用模型自身的能力来构造有用的提示，从而在新任务上更快捷地释放模型潜力。
- **多样性的重要性：**
作者强调了示例多样性在自动提示中的关键作用。通过聚类选取不同类型的问题，Auto-CoT 有效地避免了由于示例与待答问题过于相似而可能带来的错误传播。实验显示，多样化的示例集使模型对各种问题类型都有所准备，从而提高了整体稳健性和准确率。这一点在提示设计上具有普适意义：无论人工或自动构造示例，确保示例覆盖多种情况会使模型推理更可靠。
- **意义与展望：**
Auto-CoT 将零样本思维链和少样本提示相结合，在无需人工干预的情况下达到了以前只有人工精心设计才能实现的效果。这一发现为大规模应用链式思维提示打开了新思路。例如，针对每个新领域任务，我们不再需要专家逐例编写演示，模型自己就能产出训练示例，极大地提升了可扩展性。随着模型推理能力的增强和自动化提示技术的发展，我们有望看到人工智能系统在复杂推理任务上更加高效自治的表现。

### 3.2 个人思考 Personal Thoughts

- 模型生成示例的局限：Auto-CoT 的有效前提是模型具备一定的零样本推理能力。如果模型本身对某类问题的 Zero-Shot-CoT 表现较差，那么生成的示例可能也是错误百出的，从而限制了 Auto-CoT 的上限。这提示我们，随着基础模型推理能力的提升（例如更大的模型或更好的训练），Auto-CoT 的效果也会水涨船高。未来或许可以引入自检或校验机制（例如借助辅助模型判断链式推理是否正确）来提升自动示例的可靠性。
- 对任务和数据的依赖：当前 Auto-CoT 方法需要对任务有一批问题进行聚类采样，这在评估基准数据集上易于实现。但在实际应用中，如果面对单个全新问题或缺乏可用的类似问题集合，如何生成多样的示例？一种设想是让模型自行生成一组伪造的问题来作为演示（例如通过分析待答问题来自行拟出相关问题进行推理演示），但这可能引入新的不稳定性。因此如何在无现成数据的情况下应用自动思维链提示，是一个值得进一步研究的问题。
- 与其他推理方法结合：Auto-CoT 聚焦于利用文本推理链示例来提示模型，未来可探索与其它策略的融合。例如，将 Auto-CoT 生成的示例与程序化思维（Program of Thoughts, PoT）相结合，让模型在提示示例中既包含自然语言推理又包含可执行代码，以应对需要精确计算的任务。此外，与自洽性采样（Self-Consistency）等技术配合也是一个方向：或许可对自动生成的多条示例链进行交叉验证，选取最可信的推理路径，从而进一步提高最终答案的准确率。
- 对小模型的启发：文章在 GPT-3 等大型模型上验证了 Auto-CoT 的实力，那么对于中小型模型，能否用大型模型生成的思维链示例去提升它们的性能？这类似于提示领域的知识蒸馏。如果一个小模型本身不会多步推理，我们可以用强大的模型先自动构造示例，再把这些示例提供给小模型 few-shot 推理，观察其性能是否提升。这样的跨模型提示迁移思路值得尝试，可能有助于低资源场景下发挥 Auto-CoT 的价值。

---

## 4. 关联文章 Related Works

- Zero-shot CoT
- Auto CoT
- CoT-SC
- Tree of Thoughts Prompting
