---
# 基本信息
name: "The Collaboration Gap"
uri: "https://arxiv.org/abs/2511.02687"
tags: ["AI协作", "多智能体", "大型语言模型", "协作基准", "接力推理"]
type: "paper"
domain: "NLP"
authors: ["Tim R. Davidson", "Adam Fourney", "Saleema Amershi", "Robert West", "Eric Horvitz", "Ece Kamar"]
affiliations: ["EPFL", "Microsoft Research"]
year: 2025
venue: "arXiv"
language: "en"
citation: |
  @misc{davidson2025collaborationgap,
    title={The Collaboration Gap}, 
    author={Tim R. Davidson and Adam Fourney and Saleema Amershi and Robert West and Eric Horvitz and Ece Kamar},
    year={2025},
    eprint={2511.02687},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2511.02687}, 
  }

# 自定义状态与评分（可选）
importance: 4
difficulty: 3
recommend: 3
---

# The Collaboration Gap

## 1. 概览 Overview

### 1.1 个人预览 Personal Preview

> 针对多智能体协作场景，本文提出并定义了“协作差距”现象，即许多在单人任务中表现优异的模型在与自身协作时性能显著下降。作者通过构建专门基准来定量测量协作能力，从而揭示是否存在模型在协作情景下性能系统性下降的问题。此外，作者还提出了一种新的协作策略“接力推理”，通过实验证明这一策略能显著提高较弱模型的协作性能。

### 1.2 内容简介 Description

- **研究背景 Research Background：**
随着 AI 系统朝着多智能体协同方向发展，人们将越来越多地依赖由多个独立智能体组成的系统，这些智能体拥有不同的信息、权限和工具。然而，目前大多数研究和基准侧重于单智能体能力或人机协作，对智能体间的协作关注较少。已有的一些多智能体系统实践往往依赖预先设定的通信协议或中心化的调度，这在开放环境下缺乏灵活性。
- **研究目标 Research Objectives：**
本文旨在评估和分析当代 LLM 在多智能体协作任务中的表现差异，找出影响协作效率的因素，并探索提升协作效果的方法。作者希望通过构建专门基准来定量测量协作能力，从而揭示是否存在模型在协作情景下性能系统性下降的问题，即提出并验证“**协作差距**”假设。另一个目标是在发现协作退化现象后，探索新的协作策略如“接力推理（relay inference）”来改善多智能体协作表现。
- **主要贡献 Main Contributions：**
(1) 提出并定义了“协作差距”现象，即许多在单人任务中表现优异的模型在与自身协作时性能显著下降，并通过大规模实验证实这一点（这一现象在小型蒸馏模型中尤为严重）。
(2) 解析异质智能体协作的动态性，发现任务执行性能与哪一个智能体发起交互密切相关，顺序效应显著。
(3) 基于上述发现，提出“接力推理”协作策略：由更强的模型先完成任务初步步骤后再交由较弱模型接力，以此弥补协作退化。实验证明这一最小介入策略能显著提高较弱模型的协作性能。作者据此指出，协作能力是当前训练策略未覆盖的独立能力维度，协作差距将成为部署多智能体系统时的关键障碍。

---

## 2. 关键信息 Key Information

### 2.1 核心思想与方法 Main Ideas & Methods

- **核心思想：**
要说明 LLM 在协作场景下表现出的退化现象，即“协作差距”，仅与协作能力而非其它能力有关，即有效协作是一种需要专门研究与培养的独立能力。需要将协作能力视作模型能力的新维度进行评估和改进，即在需要协作的应用场景中测试智能体协作与否的效果。
- **实现方法：**
作者设计了一个可扩展的迷宫求解基准来专门测试模型的协作能力。在该任务中，两个智能体需要通过自然语言合作寻找迷宫出口。迷宫被拆分成两份不完整的信息，各智能体各自掌握一部分，从而创造部分可观测环境，需要彼此交流分享线索才能解题。
这一基准具备以下特性：
&emsp;&emsp;(1) 隔离协作能力影响的设计（通过对比单人和双人条件）。
&emsp;&emsp;(2) 可调节的任务复杂度（迷宫大小、墙壁密度等参数可变）。
&emsp;&emsp;(3) 可扩展的自动评分机制（引入第三方模型作为裁判来自动判定解题成功与否）。
&emsp;&emsp;(4) 自然的对话格式（不强制固定输出格式以模拟真实协作场景）。
基于此基准，作者对 32 个当前领先的开源/闭源 LLM 模型分别进行了单独、同质成对、和异质成对三种模式下的大规模实验比较，以系统分析协作对性能的影响。

### 2.2 实验设置与结果 Experimental Settings & Results

- **实验设置 Experimental Settings：**
实验采用的迷宫任务为 $6\times6$ 网格迷宫，智能体的目标是协力找到从起点“@”到终点“*”的路径。每个智能体只能看到迷宫的一部分（各自地图上有部分格子未知以“?”表示），因此双方需要通过语言交流各自视野来获得完整信息。双方轮流提出移动提议，每一步移动需双方同意才能执行。
![Core System Diagram](./Resources/The%20Collaboration%20Gap%20-%20Core%20System%20Diagram.png)
为了评估协作效果，引入了自动评分机制：在对话完成或达到一定步数后，使用预训练模型充当“裁判”读取双方对话和行动提议，以判断迷宫是否成功解出并计算加权得分。
作者在不同条件下进行对比实验：
&emsp;&emsp;(1) 单人模式：由单个模型在获得完整迷宫或部分迷宫信息的情况下独立求解，用于测定基线能力。
&emsp;&emsp;(2) 同质协作：两个相同的模型各掌握互补的半份迷宫，通过对话协作求解。
&emsp;&emsp;(3) 异质协作：两个不同模型配对协作（涵盖模型规模、家族的多种组合）。
每种条件下均进行了多次迷宫求解实验，以获得平均性能和置信区间。作者特别关注模型大小/蒸馏、模型强弱顺序等因素对协作表现的影响。
- **实验结果 Experimental Results：**
实验揭示了清晰的“协作差距”。在单人模式下，多数模型在迷宫任务上表现良好，尤其当给予完整信息时成功率较高（加权成绩普遍超过0.5）。即使给予残缺信息由单个模型独立解决，性能只略有下降。
![Solo vs. Collaborative](./Resources/The%20Collaboration%20Gap%20-%20Experiment%201.png)
但在同质协作模式中，绝大多数模型的得分相比单人时显著降低。这一差距在体量较小或由大模型蒸馏得到的模型中尤为严重：某些单人模式下能独立解决问题的小模型在与自身协作时几乎完全失败。作者指出，这暗示当前蒸馏方法可能不仅丢失了知识长尾，还损失了模型的协作推理能力。
![Heterogeneous Collaboration](./Resources/The%20Collaboration%20Gap%20-%20Experiment%202.png)
在异质协作中，结果同样耐人寻味。总体而言，较强模型的性能上限决定了组合的最好结果，但如果让较弱模型先行动，常导致性能无法达到强模型单独的水平。相反，若由强模型先发起对话建立共享框架，则合作效果明显提升。例如，强模型 o3 与弱模型 gpt-4.1-mini 配对时，o3 先手的平均成绩 (0.77) 远高于弱模型先手时的成绩 (0.62)。另外，不同模型家族间的协作也呈现有趣现象：某些模型对自家模型有“偏好”或默契，当跨模型家族合作时未必能充分利用彼此优势。
最后，作者提出并验证了“接力推理”策略的有效性：在异质组合中引入强模型的初始指导可以大幅缩小协作差距。具体而言，让强模型先参与对话 1-2 个回合后再由两个弱模型继续，弱模型的最终成绩显著提高，甚至接近强模型带领合作的水平。反之，如果让弱模型先交互数轮后再引入强模型救场，强模型也难以扭转先前不良沟通导致的劣势。这些结果表明初始协作阶段对最终成效至关重要，适当的策略能有效激发弱模型的潜在能力，缓解协作退化。

---

## 3 分析思考 Analysis & Thoughts

### 3.1 文章结论 Conclusions

- **协作能力的独立性：**
本文通过大规模实验证明，智能体协作能力是模型能力的独立维度，当前的预训练和微调策略并未有效培养这方面的技能。这一“协作差距”现象为多智能体 AI 系统的安全有效部署敲响警钟——即使单个模型能力出众，协作失效仍可能成为系统瓶颈。

- **意义与展望：**
作者强调，应对协作挑战需要在未来工作中做出改变。他们的发现表明未来落地多智能体系统时应当注意以下几点：
&emsp;&emsp;(1) “协作感知”的评估方案，将协作表现纳入基准测试指标。
&emsp;&emsp;(2) 专门的训练策略来增强模型协作能力（例如在训练中融入多智能体交互任务）。
&emsp;&emsp;(3) 巧妙的交互设计以引导模型发挥潜在协作技能。这些建议不仅适用于 AI–AI 协作，同样对人机协作有指导意义。
总的来说，本文结论呼吁社区重新审视多智能体智能的培养与评估，为构建能够真正协同工作的通用智能体铺平道路。

### 3.2 个人思考 Personal Thoughts

- 文章设计的迷宫求解这一特定任务挑战的是智能体在信息上的协作能力，而以往研究关注的往往是智能体在能力上的协作能力，这是否也属于不同维度的能力？
- 该基准虽然精巧且具有代表性，但毕竟属于抽象的二维任务环境。在更复杂开放的真实世界任务中（如多机器人协同操作、Agent之间协作编程等），协作挑战可能更为多样。未来工作可以考虑扩展任务种类，验证协作差距在其他领域是否同样存在，并考察更丰富的交互形式（包括竞争博弈、资源分配等场景）。
- 此外，作者主要比较了模型在零样本设置下的协作表现，后续或可探索有监督信号（如通过反馈强化协作）的情形，看看协作能力是否可以通过训练直接提升。
- 文章提出的“接力推理”思想，个人感觉本质上是因为 LLM 存在“迁就用户”的现象，使得后发的智能体会去迎合对齐先发的智能体，因此先发的智能体奠定的基调就格外重要。让对等的智能体角色在顺序上划分出负责规划任务与跟随完成任务两类，类比为 Leader 和 Partner，而负责统领全局的 Leader 需要能力更强是显而易见的。另外，模型在协作中出现的沟通不一致问题，表明完全的自由交互并不一定能带来交互效率的提升。

---

## 4. 关联文章 Related Works

- MCP
- A2A
- ACP


